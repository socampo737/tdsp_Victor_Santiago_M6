# -*- coding: utf-8 -*-
"""BaseModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OYK8vvtsJ9SKJAb8JXopbybvADR5UwGV

##Modelo Base / Base Model
"""

import math
import numpy as np
import pandas as pd
from collections import Counter
import csv
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
import os

from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
import imblearn
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier

from keras.models import Sequential
from keras.layers import Dense

# CALCULO DE LOS BIGOTES DE UNA LISTA DE VALORES

def bigotes(xx):
    q25 = np.quantile(xx, 0.25)
    q75 = np.quantile(xx, 0.75)
    RIC = q75 - q25
    BI = q25 - 1.5*RIC
    BS = q75 + 1.5*RIC

    minimo = xx.min()
    maximo = xx.max()

    if BI < minimo:
        BI = minimo

    if BS > maximo:
        BS = maximo

    return (BI, BS)

# BUSCA LAS COLUMNAS QUE TIENEN UN PORCENTAJE DE VACIOS MAYOR O IGUAL A UN VALOR

def columnas_vacias(dff, porcentaje):
    L = []
    b = dff.shape[0]

    for col in dff.columns:
        a = sum(dff[col].isnull())
        r = np.round(100*a/b, 2)
        if r > porcentaje:
            L.append(col)

    return L

# columnas_vacias(40)
# columnas_vacias(df_nueva, 10)

# PREPARA Google Drive
drive.mount('/gdrive')

# LECTURA DEL DATASET
ruta = '/gdrive/MyDrive/UNAL_Cobros.csv'
df = pd.read_csv(ruta, sep=";")

nbytes = os.stat(ruta).st_size
megabytes = nbytes / (1024 ** 2)
print(f"El archivo tiene {megabytes:.2f} MB")

print(type(df))

# INFORMACION DE LAS VARIABLES DEL DATASET
df.info()

# EJEMPLO DE LOS DATOS DEL DATASET
df.head()

# TAMAÑO DEL DATASET
print("Numero de filas: ", df.shape[0])
print("Numero de variables: ", df.shape[1])

# ELIMINACION DE COLUMNAS CON INFORMACION NO RELEVANTE
df2 = df.drop(['FECHA_ENVIO', 'CUST_CODE', 'NUMERO_FACTURA',
       'FECHA_DEVOLUCION', 'FECHA_FACTURA',
       'FECHA CARGA', 'EMAIL', 'IMPORTE PRODUCTO'], axis=1)

# COLUMNAS RESULTANTES DESPUES DE LA ELIMINACION
df2.columns

# VARIABLE TARGET, CORRESPONDE A COBRANZA SI/NO
df2['TARGET']

# CAMBIAR LA VARIABLE TARGET DE TIPO CATEGORICO A NUMERICO BINARIO

df2['TARGET'] = [1 if x=='SI' else 0 for x in df2['TARGET']]

df2['TARGET'][0:5]

df2

df2.info()

#OBTENEMOS LOS VALORES ESTADISTICOS BASICOS DE CADA UNA DE LAS VARIABLES
df2.describe()

df2["TARGET"].value_counts().plot(kind='barh', width=0.7, edgecolor='black')

df2["ESTADO_CLIENTE"].value_counts().plot(kind='pie', autopct='%.2f%%', wedgeprops={"linewidth": 2, "edgecolor": "white"})

sns.histplot(data=df2, x="CANTIDAD_FACTURAS", bins=10, kde=True)

# ANALISIS DE VARIABLE PERMANENCIA
Counter(df2.PERMANENCIA)

"""Como la variable PERMANENCIA tiene tantos valores vacios, la variable no sera usada."""

# BORRADO DE LA VARIABLE PERMANENCIA
df2.drop("PERMANENCIA", axis=1, inplace=True)

# ANALISIS DE VARIABLE FEU
Counter(df2.FEU)

"""Como la variable FEU tiene tantos valores vacios, la variable no sera usada."""

# BORRADO DE LA VARIABLE FEU
df2.drop("FEU", axis=1, inplace=True)

# ANALISIS DE VARIABLE TIPO_DOCUMENTO
Counter(df2.TIPO_DOCUMENTO)

"""Como la variable TIPO_DOCUMENTO tiene tantos valores vacios, la variable no sera usada."""

# BORRADO DE LA VARIABLE TIPO_DOCUMENTO
df2.drop("TIPO_DOCUMENTO", axis=1, inplace=True)

# ANALISIS DE VARIABLE FECHA_BPI
df2.FECHA_BPI

"""En la variable FECHA_BPI los valores diferentes a NaN indican que hay fecha de baja, los valores NaN indica que no.

Por tanto crearemos una nueva variable numerica llamada BAJA así:
<br><br>
Si FECHA_BPI = NaN => BAJA=0<br>
Sino => BAJA=1
"""

# CREAMOS LA VARIABLE BAJA
df2["BAJA"] = [0 if math.isnan(x) else 1 for x in df2['FECHA_BPI']]

df2[["FECHA_BPI","BAJA"]]

# ELIMINAMOS LA VARIABLE FECHA_BPI
df2.drop("FECHA_BPI", axis=1, inplace=True)

# ANALISIS DE LA VARIABLE PORTADO
Counter(df2.PORTADO)

# AJUSTE DE LOS DATOS DE PORTADO
df2['PORTADO'] = df2['PORTADO'].map({"NO" : 0,
                                  "SI" : 1,
                                  "N" : 0,
                                  "BAJAS_I " : 0,
                                  "BAJAS_II " : 0,
                                  "N/A " : 0})

# PORTADO DESPUES DE LA TRANSFORMACION
Counter(df2.PORTADO)

# ANALISIS DE LA VARIABLE ESCENARIO RECOBROS
Counter(df2.ESCENARIO_RECOBRO)

# ANALISIS DE LA VARIABLE ESCENARIO RECOBROS
def escenario(x):
  if x == "PER" or x == "FU":
    return 1
  else:
    return 0

df2["ESCENARIO_RECOBRO"]	= [escenario(x) for x in df2['ESCENARIO_RECOBRO']]

# ESCENARIO RECOBRO DESPUES DEL CAMBIO
Counter(df2.ESCENARIO_RECOBRO)

# ANALISIS DE LA VARIABLE ESTADO_CLIENTE
Counter(df2.ESTADO_CLIENTE)

"""Como la variable ESTADO_CLIENTE tiene solo dos clases usaremos el valor 1 para la clase A y el 0 para la clase B."""

# CAMBIAR LA VARIABLE ESTADO_CLIENTE DE TIPO CATEGORICO A NUMERICO BINARIO
df2["ESTADO_CLIENTE"]	= [1 if x == "A" else 0 for x in df2['ESTADO_CLIENTE']]

# TRANFORMACION DE LA VARIABLE VAP_SCF CON VALORES SI Y NO A 1 Y 0
df2["VAP_SCF"]	= [0 if x == "N" else 1 for x in df2["VAP_SCF"]]

# TRANFORMACION DE LA VARIABLE VAP_OB CON VALORES SI Y NO A 1 Y 0
df2["VAP_OB"]	= [0 if x == "N" else 1 for x in df2["VAP_OB"]]

# TRANFORMACION DE LA VARIABLE VPT CON VALORES SI Y NO A 1 Y 0
df2["VPT"]	= [0 if x == "N" else 1 for x in df2["VPT"]]

df2

# TRANSFORMACION DEL CODIGO_POSTAL TOMANDO SOLO EL CODIGO DE LA PROVINCIA
def cp(x):
  if x != "":
    return float(x)//1000
  else:
    return x

df2["CODIGO_POSTAL"] = [cp(x) for x in df2["CODIGO_POSTAL"]]

# CODIGO POSTAL TRANSFORMADO
df2["CODIGO_POSTAL"]

# ANALISIS DE LA VARIABLE EDAD
Counter(df2.EDAD)

# IMPUTACION DEL CODIGO_POSTAL
# VAMOS A USAR LA MODA DE ESTA VARIABLE POR SER UNA PROVINCIA

df2.groupby(["CODIGO_POSTAL"])["CODIGO_POSTAL"].count().sort_values(ascending=False).head(10)

# EL VALOR DE LA MODA ES EL CODIGO 28

# VAMOS A REMPLAZAR LOS VACIOS EN LAS PROVINCIA CON LA MODA, EL VALOR ES 28
df2["CODIGO_POSTAL"].fillna(value=28, inplace=True)

df2

df2.info()

# CAMBIO IMPORTE_FACTURA DE CATEGORICO A NUMERICO
df2["IMPORTE_FACTURA"] = df2["IMPORTE_FACTURA"].astype("float")

# IMPUTACION DE VALORES A LAS VARIABLES VACIAS

cols20 = columnas_vacias(df2, 20)
for columna in cols20:
    # print("10: ", columna)
    if df2[columna].dtype == "object":
        df2[columna].fillna(value="NO IDENTIFICADO", inplace=True)
        print(columna, " imputada con NO IDENTIFICADO por tener mas del 20% de vacios")
    else:
        mediana = df2[columna].median(skipna=True)  # numeric_onlybool
        df2[columna].fillna(value=mediana, inplace=True)
        print(columna, " imputada con la mediana por tener mas del 20% de vacios: ", mediana)


cols0 = columnas_vacias(df2, 0)
for columna in cols0:
    # print("0: ", columna)
    if df2[columna].dtype == "object":
        moda = df2[columna].mode()[0]
        df2[columna].fillna(value=moda, inplace=True)
        print(columna, " imputada con la moda por tener entre 0% y 20% de vacios: ", moda)
    else:
        mediana = df[columna].median(skipna=True)  # numeric_onlybool
        df2[columna].fillna(value=mediana, inplace=True)
        print(columna, " imputada con la mediana por tener entre 0% y 20% de vacios: ", mediana)

df2

# CALCULO DE LOS BIGOTES PARA VARIABLES

lista_numericas = ["CANTIDAD_FACTURAS", "IMPORTE_FACTURA", "DEUDA_TOTAL", "NUM_LINEAS_ACTIVAS"]

for columna in lista_numericas:
    BI, BS = bigotes(df2[columna])
    print("{}: {:,.2f}, {:,.2f}".format(columna, BI, BS))

# AJUSTE DE CANTIDAD_FACTURAS SEGUN EL BIGOTE
df2['CANTIDAD_FACTURAS'] = [1   if x < 1   else x for x in df2['CANTIDAD_FACTURAS']]
df2['CANTIDAD_FACTURAS'] = [3.5 if x > 3.5 else x for x in df2['CANTIDAD_FACTURAS']]

# AJUSTE DE IMPORTE_FACTURA SEGUN EL BIGOTE
df2['IMPORTE_FACTURA'] = [0      if x < 0      else x for x in df2['IMPORTE_FACTURA']]
df2['IMPORTE_FACTURA'] = [314.24 if x > 314.24 else x for x in df2['IMPORTE_FACTURA']]

# AJUSTE DE IMPORTE_FACTURA SEGUN EL BIGOTE
df2['DEUDA_TOTAL'] = [0      if x < 0      else x for x in df2['DEUDA_TOTAL']]
df2['DEUDA_TOTAL'] = [628.83 if x > 628.83 else x for x in df2['DEUDA_TOTAL']]

# AJUSTE DE IMPORTE_FACTURA SEGUN EL BIGOTE
df2['NUM_LINEAS_ACTIVAS'] = [0   if x < 0   else x for x in df2['NUM_LINEAS_ACTIVAS']]
df2['NUM_LINEAS_ACTIVAS'] = [2.5 if x > 2.5 else x for x in df2['NUM_LINEAS_ACTIVAS']]

df2["EDAD"]

# CREACION DE VARIABLES DUMMIES PARA LA EDAD
modelo_dummy = OneHotEncoder(sparse=False)
df2_dummy = modelo_dummy.fit_transform(pd.DataFrame(df2["EDAD"]))
df2_dummy = pd.DataFrame(df2_dummy, columns=["0_30", "31_50", "51_65", "MAYOR_65"])
df2_dummy

# CONCATENA DATASET NUMERICO CON EL DATASET DE DUMMIES DE LA EDAD
df3 = pd.concat([df2, df2_dummy], axis=1)
df3.sample(20)

# ELIMINA LA VARIABLE EDAD
df3.drop("EDAD", axis=1, inplace=True)

# DISTRIBUCIÓN DE LOS DATOS (HISTOGRAMAS)
fig = plt.figure(figsize = (15,8))
axes = fig.gca()
df3[["CANTIDAD_FACTURAS", "IMPORTE_FACTURA", "DEUDA_TOTAL", "NUM_LINEAS_ACTIVAS"]].hist(ax = axes);

# GRAFICA DE CORRELACION LINEAL ENTRE LAS VARIABLES NUMERICAS

sns.set_theme(style="ticks")

# df = sns.load_dataset("penguins")

lista_numericas = ["CANTIDAD_FACTURAS", "IMPORTE_FACTURA", "DEUDA_TOTAL", "NUM_LINEAS_ACTIVAS", 'TARGET']

sns.pairplot(df3[lista_numericas], hue='TARGET')

sns.heatmap(df2.corr(), annot=False, cmap="icefire")

# SEPARACION DE X Y
df3_X = df3.drop("TARGET", axis=1)
df3_y = df3["TARGET"]

# ESCALADO DE VARIABLES NUMERICAS
modelo_sc = MinMaxScaler()

df3_X_escalado = modelo_sc.fit_transform(df3_X)

df4_X = pd.DataFrame(df3_X_escalado, columns=df3_X.columns)

df4_X.sample(5)

# OBSERVACIONES POR CATEFORIA EN LA VARIABLE TARGET
sns.countplot(x='TARGET', data=pd.DataFrame(df3_y))

plt.title("Datos desbalanceados");

# DATOS TOTALES SIN BALANCEAR
print(Counter(df3_y))

"""Como podemos ver la cantidad de observaciones de las dos categorías es bastante diferente, si hacemos el modelo con estas cantidades posiblemente obtendremos buena Exactitud ya que el modelo clasifica bien los registros de forma global, pero observando detenidamente nos daremos cuenta que el modelo está clasificando de buena forma la clase mayoritaria mientras que la clase minoritaria sería clasificada pobremente.
Para evitar este problema debemos usar un método que balancee las clases o que aplique una penalización sobre las mismas. Para nuestro caso balanceamos la variable usando el método SMOTE (Synthetic Minority Over-sample Tecnique) que nos permitirá crear registros sintéticos para la clase minoritaria.
"""

# BALANCE DE VARIABLE TARGET (OVERSAMPLING)
oversample = SMOTE()      # SMOTE(sampling_strategy=0.1)
X_bal, y_bal = oversample.fit_resample(df4_X, df3_y)

# OBSERVACIONES POR CATEFORIA EN LA VARIABLE TARGET DESPUES DEL BALANCE
sns.countplot(x='TARGET', data=pd.DataFrame(y_bal))

plt.title("Datos balanceados");

# DATOS TOTALES SIN BALANCEAR
print(Counter(y_bal))

# EJEMPLO DE LOS DATOS
X_bal.sample(10)

X_bal.info()

# DIVISION DE LA MUESTRA EN DATASET DE ENTRENAMIENTO Y PRUEBA (80%, 20%)
X_ent, X_pru, y_ent, y_pru = train_test_split(X_bal,
                                              y_bal,
                                              test_size=0.2,
                                              random_state=1)

print(X_ent.shape, X_pru.shape, y_ent.shape, y_pru.shape)

y_ent.info()

y_pru.info()

#NUMERO DE VARIABLES
nvars = X_ent.shape[1]
nvars

# RANDOM FOREST

modelo_base = RandomForestClassifier(criterion='gini', n_estimators=500, max_depth=10, random_state=123)

modelo_base.fit(X_ent, y_ent)

#y_pred = modelo_base.predict(X_pru)

print("Entrenamiento: {:.1f}".format(100*modelo_base.score(X_ent, y_ent)))

print("Prueba: {:.1f}".format(100*modelo_base.score(X_pru, y_pru)))