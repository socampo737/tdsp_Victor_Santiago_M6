# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1edpCaRYQEjqLEQ9PUla9uet0vKwWVbm1

##Preprocesamiento y análisis descriptivo / preprocessing
"""

# Commented out IPython magic to ensure Python compatibility.
import math
import numpy as np
import pandas as pd
from collections import Counter
import csv
from google.colab import drive
# %matplotlib inline
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
import seaborn as sns
import os
from sklearn.preprocessing import OneHotEncoder

"""### **Lectura de datos**"""

# PREPARA GOOGLE DRIVE
drive.mount('/gdrive')

# LECTURA DEL DATASET
ruta = '/gdrive/MyDrive/UNAL_Cobros.csv'
df = pd.read_csv(ruta, sep=";")

nbytes = os.stat(ruta).st_size
megabytes = nbytes / (1024 ** 2)
print(f"El archivo tiene {megabytes:.2f} MB")

print(type(df))

# INFORMACION DE LAS VARIABLES DEL DATASET
df.info()

# EJEMPLO DE LOS DATOS DEL DATASET
df.head()

# TAMAÑO DEL DATASET
print("Numero de filas: ", df.shape[0])
print("Numero de variables: ", df.shape[1])

"""### **Transformación de datos**"""

# ELIMINACION DE COLUMNAS CON INFORMACION NO RELEVANTE
df2 = df.drop(['FECHA_ENVIO', 'CUST_CODE', 'NUMERO_FACTURA',
       'FECHA_DEVOLUCION', 'FECHA_FACTURA',
       'FECHA CARGA', 'EMAIL', 'IMPORTE PRODUCTO'], axis=1)

# COLUMNAS RESULTANTES DESPUES DE LA ELIMINACION
df2.columns

# VARIABLE TARGET, CORRESPONDE A COBRANZA SI/NO
df2['TARGET']

# CAMBIAR LA VARIABLE TARGET DE TIPO CATEGORICO A NUMERICO BINARIO

df2['TARGET'] = [1 if x=='SI' else 0 for x in df2['TARGET']]

df2['TARGET'][0:5]

df2

"""### **Análisis Exploratorio de datos**

El primer paso en todo proyecto de Deep Learning es **entender** los datos. Esto implica, entre otras, entender las distribuciones, el rango de valores que tienen y si hay o no datos faltantes.
"""

df2.info()

#OBTENEMOS LOS VALORES ESTADISTICOS BASICOS DE CADA UNA DE LAS VARIABLES
df2.describe()

df2["TARGET"].value_counts().plot(kind='barh', width=0.7, edgecolor='black')

df2["ESTADO_CLIENTE"].value_counts().plot(kind='pie', autopct='%.2f%%', wedgeprops={"linewidth": 2, "edgecolor": "white"})

sns.histplot(data=df2, x="CANTIDAD_FACTURAS", bins=10, kde=True)

# ANALISIS DE VARIABLE PERMANENCIA
Counter(df2.PERMANENCIA)

"""Como la variable PERMANENCIA tiene tantos valores vacios, la variable no sera usada."""

# BORRADO DE LA VARIABLE PERMANENCIA
df2.drop("PERMANENCIA", axis=1, inplace=True)

# ANALISIS DE VARIABLE FEU
Counter(df2.FEU)

"""Como la variable FEU tiene tantos valores vacios, la variable no sera usada."""

# BORRADO DE LA VARIABLE FEU
df2.drop("FEU", axis=1, inplace=True)

# ANALISIS DE VARIABLE TIPO_DOCUMENTO
Counter(df2.TIPO_DOCUMENTO)

"""Como la variable TIPO_DOCUMENTO tiene tantos valores vacios, la variable no sera usada."""

# BORRADO DE LA VARIABLE TIPO_DOCUMENTO
df2.drop("TIPO_DOCUMENTO", axis=1, inplace=True)

# ANALISIS DE VARIABLE FECHA_BPI
df2.FECHA_BPI

"""En la variable FECHA_BPI los valores diferentes a NaN indican que hay fecha de baja, los valores NaN indica que no.

Por tanto crearemos una nueva variable numerica llamada BAJA así:
<br><br>
Si FECHA_BPI = NaN => BAJA=0<br>
Sino => BAJA=1
"""

# CREAMOS LA VARIABLE BAJA
df2["BAJA"] = [0 if math.isnan(x) else 1 for x in df2['FECHA_BPI']]

df2[["FECHA_BPI","BAJA"]]

# ELIMINAMOS LA VARIABLE FECHA_BPI
df2.drop("FECHA_BPI", axis=1, inplace=True)

# ANALISIS DE LA VARIABLE PORTADO
Counter(df2.PORTADO)

# AJUSTE DE LOS DATOS DE PORTADO
df2['PORTADO'] = df2['PORTADO'].map({"NO" : 0,
                                  "SI" : 1,
                                  "N" : 0,
                                  "BAJAS_I " : 0,
                                  "BAJAS_II " : 0,
                                  "N/A " : 0})

# PORTADO DESPUES DE LA TRANSFORMACION
Counter(df2.PORTADO)

# ANALISIS DE LA VARIABLE ESCENARIO RECOBROS
Counter(df2.ESCENARIO_RECOBRO)

# ANALISIS DE LA VARIABLE ESCENARIO RECOBROS
def escenario(x):
  if x == "PER" or x == "FU":
    return 1
  else:
    return 0

df2["ESCENARIO_RECOBRO"]	= [escenario(x) for x in df2['ESCENARIO_RECOBRO']]

# ESCENARIO RECOBRO DESPUES DEL CAMBIO
Counter(df2.ESCENARIO_RECOBRO)

# ANALISIS DE LA VARIABLE ESTADO_CLIENTE
Counter(df2.ESTADO_CLIENTE)

"""Como la variable ESTADO_CLIENTE tiene solo dos clases usaremos el valor 1 para la clase A y el 0 para la clase B."""

# CAMBIAR LA VARIABLE ESTADO_CLIENTE DE TIPO CATEGORICO A NUMERICO BINARIO
df2["ESTADO_CLIENTE"]	= [1 if x == "A" else 0 for x in df2['ESTADO_CLIENTE']]

# TRANFORMACION DE LA VARIABLE VAP_SCF CON VALORES SI Y NO A 1 Y 0
df2["VAP_SCF"]	= [0 if x == "N" else 1 for x in df2["VAP_SCF"]]

# TRANFORMACION DE LA VARIABLE VAP_OB CON VALORES SI Y NO A 1 Y 0
df2["VAP_OB"]	= [0 if x == "N" else 1 for x in df2["VAP_OB"]]

# TRANFORMACION DE LA VARIABLE VPT CON VALORES SI Y NO A 1 Y 0
df2["VPT"]	= [0 if x == "N" else 1 for x in df2["VPT"]]

df2

# TRANSFORMACION DEL CODIGO_POSTAL TOMANDO SOLO EL CODIGO DE LA PROVINCIA
def cp(x):
  if x != "":
    return float(x)//1000
  else:
    return x

df2["CODIGO_POSTAL"] = [cp(x) for x in df2["CODIGO_POSTAL"]]

# CODIGO POSTAL TRANSFORMADO
df2["CODIGO_POSTAL"]

# ANALISIS DE LA VARIABLE EDAD
Counter(df2.EDAD)

# IMPUTACION DEL CODIGO_POSTAL
# VAMOS A USAR LA MODA DE ESTA VARIABLE POR SER UNA PROVINCIA

df2.groupby(["CODIGO_POSTAL"])["CODIGO_POSTAL"].count().sort_values(ascending=False).head(10)

# EL VALOR DE LA MODA ES EL CODIGO 28

# VAMOS A REMPLAZAR LOS VACIOS EN LAS PROVINCIA CON LA MODA, EL VALOR ES 28
df2["CODIGO_POSTAL"].fillna(value=28, inplace=True)

df2

df2.info()

# CAMBIO IMPORTE_FACTURA DE CATEGORICO A NUMERICO
df2["IMPORTE_FACTURA"] = df2["IMPORTE_FACTURA"].astype("float")

# IMPUTACION DE VALORES A LAS VARIABLES VACIAS

cols20 = columnas_vacias(df2, 20)
for columna in cols20:
    if df2[columna].dtype == "object":
        df2[columna].fillna(value="NO IDENTIFICADO", inplace=True)
        print(columna, " imputada con NO IDENTIFICADO por tener mas del 20% de vacios")
    else:
        mediana = df2[columna].median(skipna=True)  # numeric_onlybool
        df2[columna].fillna(value=mediana, inplace=True)
        print(columna, " imputada con la mediana por tener mas del 20% de vacios: ", mediana)


cols0 = columnas_vacias(df2, 0)
for columna in cols0:
    if df2[columna].dtype == "object":
        moda = df2[columna].mode()[0]
        df2[columna].fillna(value=moda, inplace=True)
        print(columna, " imputada con la moda por tener entre 0% y 20% de vacios: ", moda)
    else:
        mediana = df[columna].median(skipna=True)  # numeric_onlybool
        df2[columna].fillna(value=mediana, inplace=True)
        print(columna, " imputada con la mediana por tener entre 0% y 20% de vacios: ", mediana)

df2

# CALCULO DE LOS BIGOTES PARA VARIABLES

lista_numericas = ["CANTIDAD_FACTURAS", "IMPORTE_FACTURA", "DEUDA_TOTAL", "NUM_LINEAS_ACTIVAS"]

for columna in lista_numericas:
    BI, BS = bigotes(df2[columna])
    print("{}: {:,.2f}, {:,.2f}".format(columna, BI, BS))

# AJUSTE DE CANTIDAD_FACTURAS SEGUN EL BIGOTE
df2['CANTIDAD_FACTURAS'] = [1   if x < 1   else x for x in df2['CANTIDAD_FACTURAS']]
df2['CANTIDAD_FACTURAS'] = [3.5 if x > 3.5 else x for x in df2['CANTIDAD_FACTURAS']]

# AJUSTE DE IMPORTE_FACTURA SEGUN EL BIGOTE
df2['IMPORTE_FACTURA'] = [0      if x < 0      else x for x in df2['IMPORTE_FACTURA']]
df2['IMPORTE_FACTURA'] = [314.24 if x > 314.24 else x for x in df2['IMPORTE_FACTURA']]

# AJUSTE DE IMPORTE_FACTURA SEGUN EL BIGOTE
df2['DEUDA_TOTAL'] = [0      if x < 0      else x for x in df2['DEUDA_TOTAL']]
df2['DEUDA_TOTAL'] = [628.83 if x > 628.83 else x for x in df2['DEUDA_TOTAL']]

# AJUSTE DE IMPORTE_FACTURA SEGUN EL BIGOTE
df2['NUM_LINEAS_ACTIVAS'] = [0   if x < 0   else x for x in df2['NUM_LINEAS_ACTIVAS']]
df2['NUM_LINEAS_ACTIVAS'] = [2.5 if x > 2.5 else x for x in df2['NUM_LINEAS_ACTIVAS']]

df2["EDAD"]

# CREACION DE VARIABLES DUMMIES PARA LA EDAD
modelo_dummy = OneHotEncoder(sparse=False)
df2_dummy = modelo_dummy.fit_transform(pd.DataFrame(df2["EDAD"]))
df2_dummy = pd.DataFrame(df2_dummy, columns=["0_30", "31_50", "51_65", "MAYOR_65"])
df2_dummy

# CONCATENA DATASET NUMERICO CON EL DATASET DE DUMMIES DE LA EDAD
df3 = pd.concat([df2, df2_dummy], axis=1)
df3.sample(20)

# ELIMINA LA VARIABLE EDAD
df3.drop("EDAD", axis=1, inplace=True)

# DISTRIBUCIÓN DE LOS DATOS (HISTOGRAMAS)
fig = plt.figure(figsize = (15,8))
axes = fig.gca()
df3[["CANTIDAD_FACTURAS", "IMPORTE_FACTURA", "DEUDA_TOTAL", "NUM_LINEAS_ACTIVAS"]].hist(ax = axes);

# GRAFICA DE CORRELACION LINEAL ENTRE LAS VARIABLES NUMERICAS

sns.set_theme(style="ticks")

# df = sns.load_dataset("penguins")

lista_numericas = ["CANTIDAD_FACTURAS", "IMPORTE_FACTURA", "DEUDA_TOTAL", "NUM_LINEAS_ACTIVAS", 'TARGET']

sns.pairplot(df3[lista_numericas], hue='TARGET')

sns.heatmap(df2.corr(), annot=True, cmap="icefire")